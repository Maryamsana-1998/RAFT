{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040546b9-2c3e-4652-8daf-af633d133ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import struct\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "from typing import List, Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Â RAFT + helpers --------------------------------------------------------------\n",
    "from raft import RAFT                      #Â <â€‘ ensure RAFT repo in PYTHONPATH\n",
    "from utils.utils import InputPadder\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import flowiz as fz\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Config ===\n",
    "videos = [\"Beauty\", \n",
    "    \"HoneyBee\", \n",
    "    \"ReadySteadyGo\", \n",
    "    \"YachtRide\", \n",
    "    \"Bosphorus\", \n",
    "    \"Jockey\", \n",
    "    \"ShakeNDry\"\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922b1f16-ed92-4c91-af15-d9a2229a80b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# compute_flows_gop.py\n",
    "# -----------------------------------------------------------\n",
    "import os, glob, argparse, struct\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# ------------- import RAFT + helpers -----------------------\n",
    "from raft import RAFT\n",
    "from utils.utils import InputPadder\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Utilities you already provided (kept unchanged)\n",
    "# -----------------------------------------------------------\n",
    "def write_flo_file(flow: np.ndarray, filename: str) -> None:\n",
    "    \"\"\"Save optical flow to Middlebury .flo\"\"\"\n",
    "    assert flow.ndim == 3 and flow.shape[2] == 2, \"Flow must have shape (H, W, 2)\"\n",
    "    magic = 202021.25\n",
    "    h, w = flow.shape[:2]\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(struct.pack(\"f\", magic))\n",
    "        f.write(struct.pack(\"i\", w))\n",
    "        f.write(struct.pack(\"i\", h))\n",
    "        f.write(flow.astype(np.float32).tobytes())\n",
    "\n",
    "def load_image(path: str, device: torch.device) -> torch.Tensor:\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    tensor = torch.from_numpy(img).permute(2, 0, 1).float().unsqueeze(0) / 255.0\n",
    "    return tensor.to(device)\n",
    "\n",
    "def process_batch(model: torch.nn.Module,\n",
    "                  pairs: List[Tuple[str, str]],\n",
    "                  out_paths: List[str],\n",
    "                  device: torch.device) -> None:\n",
    "    imgs1, imgs2, unpads = [], [], []\n",
    "    for ref_path, tgt_path in pairs:\n",
    "        ref = load_image(ref_path, device)\n",
    "        tgt = load_image(tgt_path, device)\n",
    "        padder = InputPadder(ref.shape)\n",
    "        ref, tgt = padder.pad(ref, tgt)\n",
    "        imgs1.append(ref)\n",
    "        imgs2.append(tgt)\n",
    "        unpads.append(padder.unpad)\n",
    "\n",
    "    imgs1 = torch.cat(imgs1, dim=0)\n",
    "    imgs2 = torch.cat(imgs2, dim=0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, flows = model(imgs1, imgs2, iters=20, test_mode=True)\n",
    "\n",
    "    for flow, unpad, out_path in zip(flows, unpads, out_paths):\n",
    "        flow = unpad(flow[None])[0].permute(1, 2, 0).cpu().numpy()\n",
    "        write_flo_file(flow, out_path)\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# ----------------- CONFIG ----------------------------------\n",
    "VIDEOS   = [\"Beauty\", \"HoneyBee\", \"ReadySteadyGo\", \"YachtRide\",\n",
    "            \"Bosphorus\", \"Jockey\", \"ShakeNDry\"]\n",
    "GOPS     = [4, 8, 16]\n",
    "BASE_DIR = \"/data/maryam.sana/Ultra_Perceptual_Video_Compression/data/UVG\"\n",
    "CKPT     = \"models/raft-sintel.pth\"             # <-- put RAFT ckpt here\n",
    "GPU_COUNT   = 2                                   # e.g. 2 GPUs\n",
    "MAX_WORKERS = 8                                   # CPU workers per job\n",
    "BATCH_SIZE  = 8                                   # flow pairs per RAFT forward\n",
    "# RES_FOLDER  = \"512x512\"                           # images are already 512x512\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def build_tasks() -> List[Tuple[str,str,str,int]]:\n",
    "    \"\"\"Return list of (ref, tgt, flo_out, gpu_id) tuples.\"\"\"\n",
    "    tasks = []\n",
    "    for video in VIDEOS:\n",
    "        for gop in GOPS:\n",
    "            img_dir = Path(BASE_DIR) / video / \"images\"\n",
    "            flow_dir = img_dir / f\"optical_flow_gop_{gop}\"\n",
    "            flow_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            frames = sorted(img_dir.glob(\"*.png\"))\n",
    "            total = len(frames)\n",
    "\n",
    "            for i in range(0, total, gop):\n",
    "                if i + gop >= total:\n",
    "                    break                     # skip incomplete GOP\n",
    "                ref = frames[i]               # anchor frame\n",
    "                for off in range(1, gop):\n",
    "                    tgt = frames[i + off]\n",
    "                    name = f\"flow_{i:04d}_{i+off:04d}\"\n",
    "                    flo_out = flow_dir / f\"{name}.flo\"\n",
    "                    # round-robin GPU\n",
    "                    gpu_id = len(tasks) % GPU_COUNT\n",
    "                    tasks.append((str(ref), str(tgt), str(flo_out), gpu_id))\n",
    "    return tasks\n",
    "\n",
    "# -------------- Worker wrapper -----------------------------\n",
    "def flow_worker(batch: List[Tuple[str,str,str,int]]) -> str:\n",
    "    \"\"\"Compute flows for a list of pairs on the assigned GPU.\"\"\"\n",
    "    gpu_id = batch[0][3]                         # all pairs share same GPU\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    # load RAFT once per worker\n",
    "    raft_args = argparse.Namespace(small=False, mixed_precision=False,\n",
    "                                   alternate_corr=False, model=CKPT)\n",
    "    model = RAFT(raft_args)\n",
    "    state = torch.load(CKPT, map_location=device)\n",
    "    state = {k[7:] if k.startswith('module.') else k: v for k, v in state.items()}\n",
    "    model.load_state_dict(state, strict=False)\n",
    "    model.to(device).eval()\n",
    "\n",
    "    # prepare batch lists\n",
    "    pairs, outs = [], []\n",
    "    for ref, tgt, flo_out, _ in batch:\n",
    "        if Path(flo_out).exists():\n",
    "            continue\n",
    "        pairs.append((ref, tgt))\n",
    "        outs.append(flo_out)\n",
    "\n",
    "    if pairs:\n",
    "        process_batch(model, pairs, outs, device)\n",
    "    return f\"GPU{gpu_id}: {len(pairs)} flows written.\"\n",
    "\n",
    "# -------------- Main ---------------------------------------\n",
    "def main():\n",
    "    tasks = build_tasks()\n",
    "    if not tasks:\n",
    "        print(\"No work to do. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # group tasks into mini-batches\n",
    "    batched_tasks = []\n",
    "    for i in range(0, len(tasks), BATCH_SIZE):\n",
    "        batched_tasks.append(tasks[i:i+BATCH_SIZE])\n",
    "\n",
    "    print(f\"Total flow pairs: {len(tasks)} | Batches: {len(batched_tasks)}\")\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=MAX_WORKERS) as exe:\n",
    "        futures = [exe.submit(flow_worker, batch) for batch in batched_tasks]\n",
    "        for f in tqdm(as_completed(futures), total=len(futures), desc=\"Optical-Flow\"):\n",
    "            _ = f.result()  # could log if needed\n",
    "\n",
    "    print(\"ðŸŽ‰ All optical-flow computations completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
